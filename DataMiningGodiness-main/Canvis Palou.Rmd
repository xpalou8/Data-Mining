---
title: "Main"
output:
  pdf_document: default
  html_document: default
date: '2022-12-11'
---

```{r setup, include=FALSE, echo=FALSE, results='hide', message=FALSE, warning=FALSE, fig.show='hide'}
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
library('corrplot')
library('ggplot2')
library('Hmisc')
library('moments')
library('dendextend')
library('countrycode')
library('ggthemes') # Load
library('dplyr')
library('tidyverse')
library('cluster')
library('factoextra')
library('knitr')
```

```{r echo=FALSE, results=FALSE}
salaries= read.csv("AI_MLsalaries.csv")
my_data <- salaries
```

```{r echo=FALSE, include=FALSE, echo=FALSE, results = FALSE, message=FALSE, warning=FALSE, fig.show='hide'}
#summarizing the data
str(my_data)
summary(my_data)
```

```{r echo=FALSE}
auxiliar <- my_data
my_data[sapply(my_data, is.character)] <- data.matrix(my_data[sapply(my_data, is.character)])
plot(my_data$salary_in_usd)
hist(my_data$salary_in_usd)
```


```{r echo=FALSE}
#removing outliers
boxplot(my_data$salary_in_usd)
quartiles1 <- quantile(my_data$salary_in_usd, probs=c(.01, .90), na.rm = FALSE)
IQR <- IQR(my_data$salary_in_usd)
 
Lower1 <- quartiles1[1] - 1.5*IQR
Upper1 <- quartiles1[2] + 1.5*IQR
 
data_no_outlier <- subset(my_data,my_data$salary_in_usd > Lower1 & my_data$salary_in_usd < Upper1)
boxplot(data_no_outlier$salary_in_usd)
hist(data_no_outlier$salary_in_usd)
```


```{r echo=FALSE}
plot(data_no_outlier$salary_in_usd)
```

```{r echo=FALSE}
salaTitle <-  data_no_outlier[, c(4, 5)]
summary(salaTitle)
plot(salaTitle)
```



```{r echo=FALSE}
summary(data_no_outlier$experience_level)
summary(data_no_outlier$employee_residence)
summary(data_no_outlier$employment_type)
summary(data_no_outlier$company_size)
summary(data_no_outlier$remote_ratio)
summary(data_no_outlier$job_title)
```

plot de los salarios por experiencia diferenciado en años
```{r echo=FALSE}
plot(data_no_outlier$company_size, data_no_outlier$salary_in_usd , col=data_no_outlier$company_size, xlab="company_size", ylab="salary" )
```

```{r echo=FALSE}
corrplot(cor(data_no_outlier), method = "color", type = "upper")
```
# DATA CLEANING

```{r echo=FALSE}
#reiniciar los datos
data_no_outlier <- read.csv("AI_MLsalaries.csv",stringsAsFactors = TRUE)

#removing outliers
quartiles1 <- quantile(data_no_outlier$salary_in_usd, probs=c(.01, .90), na.rm = FALSE)
IQR <- IQR(data_no_outlier$salary_in_usd)
 
Lower1 <- quartiles1[1] - 1.5*IQR
Upper1 <- quartiles1[2] + 1.5*IQR
 
data_no_outlier <- subset(data_no_outlier,data_no_outlier$salary_in_usd > Lower1 & data_no_outlier$salary_in_usd < Upper1)

#eliminating columns
data_no_outlier["salary"] <- NULL
data_no_outlier["employee_residence"] <- NULL
data_no_outlier["salary_currency"] <- NULL

#eliminating not FT
head(data_no_outlier)
data_no_outlier <- data_no_outlier[data_no_outlier$employment_type == "FT",]

#remote_ratio as factor
data_no_outlier["remote_ratio"] <- as.factor(data_no_outlier$remote_ratio)
data_no_outlier["work_year"] <- as.factor(data_no_outlier$work_year)
#NR -> no remote work, PR -> partially remote, FR -> fully remtote
levels(data_no_outlier$remote_ratio) <- list(NR  = "0", PR = "50", FR = "100")

#grouping by continents
data_no_outlier$continent <- countrycode(sourcevar = data_no_outlier[, "company_location"],
                            origin = "iso2c",
                            destination = "continent")
data_no_outlier$continent[data_no_outlier$company_location == "CA" | data_no_outlier$company_location == "US"] <- "North America"
data_no_outlier$continent = as.factor(data_no_outlier$continent)

#gruouping jobs (for clustering approach)
data_no_outlier$job_title_grouped <- data_no_outlier$job_title
data_no_outlier[grepl("BI", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "BI Analyst"
data_no_outlier[grepl("Data Analy", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Analyst"
data_no_outlier[grepl("Sci", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Scientist"
data_no_outlier[grepl("Machine Learning", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "ML Engineer"
data_no_outlier[grepl("Data Engi", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Engineer"
data_no_outlier[grepl("NLP", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Engineer"
data_no_outlier[grepl("Analytics", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Engineer"
data_no_outlier[grepl("Research", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Engineer"
data_no_outlier[grepl("ETL", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Engineer"
data_no_outlier[grepl("Data Operations", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Engineer"
data_no_outlier[grepl("Computer Vision", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "3D Computer Vision Researcher"
data_no_outlier[grepl("Data Architect", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Architect"
data_no_outlier[grepl("Head of", data_no_outlier$job_title_grouped, fixed=TRUE),]$job_title_grouped <- "Data Manager"
data_no_outlier$job_title_grouped <- factor(data_no_outlier$job_title_grouped)
summary(data_no_outlier$job_title_grouped)
levels(data_no_outlier$job_title_grouped)

#agrupar los precios por rangos
data_no_outlier$quartile <- ntile(data_no_outlier$salary_in_usd, 4)
data_no_outlier["quartile"] <- as.factor(data_no_outlier$quartile)
levels(data_no_outlier$quartile) <- list(Low  = "1", Medium_low = "2", Medium_high = "3", High = "4")

str(data_no_outlier)
head(data_no_outlier)
```



```{r echo=FALSE}
summary(data_no_outlier)
summary(lm(formula = salary_in_usd ~ work_year + experience_level + job_title + remote_ratio + company_size + company_location, 
           data = data_no_outlier))
```

# CLUSTERING

## Manual Distance matrix

First of all, for us to be able to apply clustering techniques to our Job Titles, we need to create a Distance Matrix which will be used as an input in the clustering methods. To generate this Distance Matrix, we have had to investigate and do some research to deeply understand what these Job Titles consist of so we can actually know how similar they are one to another. Once we have done this first step, we have created a distance scale in which the value 0 represents total similarity between 2 Job Titles (therefore, their distance will be 0) and the value 1 represents that 2 Job Titles are completely opposite. So, with this distance scale and the research done previously, the Distance Matrix generated is the following:

Note that: CV = "Computer Vision", BI = "Business Intelligence", DAn = "Data Analyst", DAr = "Data Architect", DE = "Data Engineer", CPO = "Chief Product Officer", DSc = "Data Scientist", DSp = "Data Specialist", ML = "Machine Learning"

```{r, echo=FALSE, out.width="100%"}
# Creamos los vectores que formarÃ¡n la matriz de distancia (0 son iguales los trabajos, 1 son opuestos)
Machine_Learning <- c(0.25,	0.5,	0.5,	0.4,	0.4,	0.85,	0.5,	0.5, 0)
Data_Specialist <- c(0.75,	0.4,	0.3,	0.3,	0.3,	0.8,	0.15, 0, 0.5)
Data_Scientist <- c(0.75,	0.3,	0.15,	0.25,	0.3,	0.8, 0, 0.15, 0.5)
CPO <- c(0.9,	0.75,	0.75,	0.75,	0.8, 0, 0.8,0.8,0.85)
Data_Engineer <- c(0.8,	0.4,	0.25,	0.1, 0,0.8,0.3,0.3,0.4)
Data_Architect <- c(0.75,	0.4,	0.25, 0,0.1,0.75,0.25,0.3,0.4)
Data_Analyst <- c(0.75,	0.3, 0,0.25,0.25,0.75,0.15,0.3,0.5)
Business_Intelligence <- c(0.75, 0, 0.3,0.4,0.4,0.75,0.3,0.4,0.5)
Computer_Vision <- c(0, 0.75,0.75,0.75,0.8,0.9,0.75,0.75,0.25)

D <- c(Computer_Vision, Business_Intelligence, Data_Analyst, Data_Architect, Data_Engineer, CPO, Data_Scientist, Data_Specialist, Machine_Learning)

My_Matrix <- matrix(D, byrow=TRUE, nrow=9)
rownames(My_Matrix) <- c("CV", "BI", "DAn", "DAr", "DE", "CPO", "DSc", "DSp", "ML")
colnames(My_Matrix) <- c("CV", "BI", "DAn", "DAr", "DE", "CPO", "DSc", "DSp", "ML")

kable(My_Matrix)

Distance_Matrix <- as.dist(My_Matrix)

#mds.coor <- cmdscale(Distance_Matrix)
#plot(mds.coor[,2], mds.coor[,2], type="n", xlab="", ylab="")
#text(jitter(mds.coor[,1]), jitter(mds.coor[,2]), rownames(mds.coor), cex=2, col = c("#FF0000", "#0000FF", "#00FF00", "#FF00FF", "#FFFF00", "#00CCCC", "#000000", "#999999", #"#9900FF", "#009966"))
#abline(h=0,v=0,col="gray75")
```


## Hierarchical Clustering and K-Means methods using the Distance matrix of the Job Titles

With the Hierarchical clustering method, we are able to visualize the clusters formed by the 2 closest Job Titles in each iteration.

Finally, to assure that the clustering results are correct, we use the K-Means method so we have 2 clustering techniques that most likely produce the same result.


```{r echo=FALSE, figures-side, fig.show="hold", out.width="50%"}
hc <- hclust(Distance_Matrix)
dend <-set(as.dendrogram(hc), "branches_lwd", 4)
d1=color_branches(dend,k=5, col = c(3,1,1,4,1))
d2=color_branches(d1,k=5) # auto-coloring 5 clusters of branches.
par(mar = c(9, 4, 4, 2) + 0.1)
plot(d2, lwd=2)

kmeans.re <- kmeans(Distance_Matrix, centers = 4, nstart = 20)

fviz_cluster(kmeans.re, Distance_Matrix,
             palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#00FFFF"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw()
             )
```


Once the K-Means algorithm has finished, this plot shows us the the results are: Cluster 1: "CV", Cluster 2: "ML", Cluster3: ""BI", "DAn", "DAr", "DE", "DSc", "DSp" and Cluster4: "CPO".











